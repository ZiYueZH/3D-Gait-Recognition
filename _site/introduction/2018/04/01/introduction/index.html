<!DOCTYPE html>
<html lang="en"><!--
 __  __                __                                     __
/\ \/\ \              /\ \             __                    /\ \
\ \ \_\ \   __  __    \_\ \      __   /\_\      __       ___ \ \ \/'\
 \ \  _  \ /\ \/\ \   /'_` \   /'__`\ \/\ \   /'__`\    /'___\\ \ , <
  \ \ \ \ \\ \ \_\ \ /\ \L\ \ /\  __/  \ \ \ /\ \L\.\_ /\ \__/ \ \ \\`\
   \ \_\ \_\\/`____ \\ \___,_\\ \____\ _\ \ \\ \__/.\_\\ \____\ \ \_\ \_\
    \/_/\/_/ `/___/> \\/__,_ / \/____//\ \_\ \\/__/\/_/ \/____/  \/_/\/_/
                /\___/                \ \____/
                \/__/                  \/___/

Powered by Hydejack v7.5.0 <https://qwtel.com/hydejack/>
--><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><title>Introduction | 3D Gait Recognition</title><meta property="og:title" content="Introduction" /><meta name="author" content="Mohit | Abhijeet | Akhil" /><meta property="og:locale" content="en" /><meta name="description" content="INTERIM PROGRESS REPORT" /><meta property="og:description" content="INTERIM PROGRESS REPORT" /><link rel="canonical" href="http://localhost:4000/introduction/2018/04/01/introduction/" /><meta property="og:url" content="http://localhost:4000/introduction/2018/04/01/introduction/" /><meta property="og:site_name" content="3D Gait Recognition" /><meta property="og:image" content="http://localhost:4000/3D-Gait-Recognition/assets/img/default.jpg" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2018-04-01T00:00:00+05:30" /> <script type="application/ld+json"> {"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/icons/icon.png"},"name":"Mohit | Abhijeet | Akhil"},"@type":"BlogPosting","url":"http://localhost:4000/introduction/2018/04/01/introduction/","headline":"Introduction","dateModified":"2018-04-01T00:00:00+05:30","datePublished":"2018-04-01T00:00:00+05:30","sameAs":null,"image":"http://localhost:4000/3D-Gait-Recognition/assets/img/default.jpg","name":null,"author":{"@type":"Person","name":"Mohit | Abhijeet | Akhil"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/introduction/2018/04/01/introduction/"},"description":"INTERIM PROGRESS REPORT","@context":"http://schema.org"}</script><meta name="keywords" content=""><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="3D Gait Recognition"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="application-name" content="3D Gait Recognition"><meta name="msapplication-config" content="/assets/ieconfig.xml"><meta name="theme-color" content="#4fb1ba"><meta name="generator" content="Hydejack v7.5.0"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="3D Gait Recognition" /><link rel="alternate" href="http://localhost:4000/introduction/2018/04/01/introduction/" hreflang="en"><link rel="shortcut icon" href="/assets/icons/favicon.ico"><link rel="apple-touch-icon" href="/assets/icons/icon.png"><link rel="manifest" href="/assets/manifest.json"><link rel="dns-prefetch" href="https://fonts.googleapis.com"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link id="_disqusJS" rel="dns-prefetch" href="https://https-abhijeet2096-github-io-3d-gait-recognition.disqus.com/embed.js"><link id="_katexJS" rel="dns-prefetch" href="/assets/bower_components/katex/dist/katex.min.js"><link id="_katexCSS" rel="dns-prefetch" href="/assets/bower_components/katex/dist/katex.min.css"> <script> function stdOnEnd(n,e){n.onload=function(){this.onerror=this.onload=null,e(null,n)},n.onerror=function(){this.onerror=this.onload=null,e(new Error("Failed to load "+this.src),n)}}function ieOnEnd(n,e){n.onreadystatechange=function(){"complete"!=this.readyState&&"loaded"!=this.readyState||(this.onreadystatechange=null,e(null,n))}}window.setRelStylesheet=function(n){function e(){this.rel="stylesheet"}var o=document.getElementById(n);o.addEventListener?o.addEventListener("load",e,!1):o.onload=e},window._loaded=!1,window.loadJSDeferred=function(n,e){function o(){window._loaded=!0;var o=document.createElement("script");o.src=n,e&&(("onload"in o?stdOnEnd:ieOnEnd)(o,e),o.onload||stdOnEnd(o,e));var t=document.scripts[0];t.parentNode.insertBefore(o,t)}window._loaded?o():window.addEventListener?window.addEventListener("load",o,!1):window.onload=o}; !function(a){"use strict";var b=function(b,c,d){function e(a){return h.body?a():void setTimeout(function(){e(a)})}function f(){i.addEventListener&&i.removeEventListener("load",f),i.media=d||"all"}var g,h=a.document,i=h.createElement("link");if(c)g=c;else{var j=(h.body||h.getElementsByTagName("head")[0]).childNodes;g=j[j.length-1]}var k=h.styleSheets;i.rel="stylesheet",i.href=b,i.media="only x",e(function(){g.parentNode.insertBefore(i,c?g:g.nextSibling)});var l=function(a){for(var b=i.href,c=k.length;c--;)if(k[c].href===b)return a();setTimeout(function(){l(a)})};return i.addEventListener&&i.addEventListener("load",f),i.onloadcssdefined=l,l(f),i};"undefined"!=typeof exports?exports.loadCSS=b:a.loadCSS=b}("undefined"!=typeof global?global:this); !function(a){if(a.loadCSS){var b=loadCSS.relpreload={};if(b.support=function(){try{return a.document.createElement("link").relList.supports("preload")}catch(b){return!1}},b.poly=function(){for(var b=a.document.getElementsByTagName("link"),c=0;c<b.length;c++){var d=b[c];"preload"===d.rel&&"style"===d.getAttribute("as")&&(a.loadCSS(d.href,d,d.getAttribute("media")),d.rel=null)}},!b.support()){b.poly();var c=a.setInterval(b.poly,300);a.addEventListener&&a.addEventListener("load",function(){b.poly(),a.clearInterval(c)}),a.attachEvent&&a.attachEvent("onload",function(){a.clearInterval(c)})}}}(this); window._noPushState = false; window._noDrawer = false; </script> <!--[if gt IE 8]><!----> <script> WebFontConfig = { google: { families: ['Roboto+Slab:700','Noto+Sans:400,400i,700,700i'] }, custom: { families: ['icomoon'], urls: ['/assets/icomoon/style.css'] } }; (function(d) { var wf = d.createElement('script'), s = d.scripts[0]; wf.src = "/assets/bower_components/webfontloader/webfontloader.js"; s.parentNode.insertBefore(wf, s); }(document)); </script> <!--<![endif]--> <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:700%7CNoto+Sans:400,400i,700,700i"><style> html { font-family: Noto Sans, Helvetica, Arial, sans-serif } h1, h2, h3, h4, h5, h6, .h1, .h2, .h3, .h4, .h5, .h6, .heading { font-family: Roboto Slab, Helvetica, Arial, sans-serif }</style><link rel="stylesheet" href="/assets/icomoon/style.css"> </noscript> <!--[if gt IE 8]><!----><link rel="stylesheet" href="/assets/css/hydejack-7.5.0.css"><style id="_pageStyle"> .content a:not(.btn){color:#4fb1ba;border-color:rgba(79,177,186,0.2)}.content a:not(.btn):hover{border-color:#4fb1ba}:focus{outline-color:#4fb1ba}.btn-primary{color:#fff;background-color:#4fb1ba;border-color:#4fb1ba}.btn-primary:focus,.btn-primary.focus{box-shadow:0 0 0 3px rgba(79,177,186,0.5)}.btn-primary:hover,.btn-primary.hover{color:#fff;background-color:#409ba3;border-color:#409ba3}.btn-primary:disabled,.btn-primary.disabled{color:#fff;background-color:#4fb1ba;border-color:#4fb1ba}.btn-primary:active,.btn-primary.active{color:#fff;background-color:#409ba3;border-color:#409ba3}::selection{color:#fff;background:#4fb1ba}::-moz-selection{color:#fff;background:#4fb1ba}</style><!--<![endif]--><body><div class="navbar fixed-top"><div class="content"><div class="nav-btn-bar"> <span class="sr-only">Jump to:</span> <a id="_menu" class="nav-btn no-hover" href="#_navigation"> <span class="sr-only">Navigation</span> <span class="icon-menu"></span> </a></div></div></div><hy-push-state><main id="_main" class="content fade-in layout-post" role="main" data-color="#4fb1ba" data-theme-color="" data-image="/assets/img/back.png" data-overlay ><article id="post-introduction-2018-04-01-introduction" class="page post" role="article"><header><h1 class="post-title"> Introduction</h1><p class="post-date heading"> <time datetime="2018-04-01T00:00:00+05:30">01 Apr 2018</time> in <span>Introduction</span> on <span>Firstpost</span>, <span>Introduction</span><p class="message" > INTERIM PROGRESS REPORT</header><p>Biometrics has quickly entrenched itself as the most pertinent means for identifying and au-thenticating individuals. The traditional methods no longer ensure the security of our data inthe hands of unauthorised persons. Biometric use unique traits of an individual for its identi-fication. The biometrics can be broadly classified into two types namely wiz, 1) Physiological and 2) Behavioral biometrics. The former includes the passive features like the fingerprint,iris, face, hand veins patterns etc and the later includes are active like gait, signature voiceetc. The physiological traits of an individual are highly unique and discriminant and thus arehighly reliable. The physiological biometrics require the cooperation of the individual andalso a fully controlled setup for its high reliability. Compared to the conventional biometrics,the behavioural traits are non-invasive, non-contact and are perceivable from a larger distance.This kinds of traits do not require a cooperation of the individual, unlike the physiologicaltraits. Because of these advantages, these features gait recognition can be applied in scenarioslike surveillance, criminal investigation and access control. Gait recognition can be affectedby many factors including pose variability, clothes, bags etc. All these factors make it a reallychallenging problem to solve.<p>The majority of the research work done primarily focuses on developing the novel algo-rithms for the recognition tasks or improving efficiency and accuracy of existing solutions.These solutions are targeted over general purpose processors that are expensive, large withhigh computational power and space. Since gait recognition has a large search space and hasan extensive amount of computationally intensive operations, it is reasonable to suggest an em-bedded implementation specifically optimized to detect humans. An embedded solution wouldhave many many advantages including like low cost and integration within the embedded de-vices. Embedded devices have hardware limitations, less GPU and memory so these modelsare hosted on the cloud. Embedded devices utilise these models by sending the input data ontothe cloud. These cloud-based implementations restrict the use cases i.e device must have inter-net connectivity, data privacy etc. In order to overcome these restrictions, we need to deploythese onboard. For that model, optimization is needed to make it work on the Embedded deviceM<h1 id="background">Background</h1><p>Gait is the study of the human locomotion or in other words, it’s the manner in which you walk and run. Gait features are an important bio-metric feature for the human identification. It has demonstrated an immense potential for use in the human identification systems. It has been seen that every individual has a particular style of walking which can be used as an important trait to distinguish him from other humans. This has been used for the identification since a long time. The suitability of the gait for the human identification is because it can be perceived from a distance as well as to its non-invasive nature. A huge amount of work has been done in the field of gait recognition. There are two major approaches to the problem one being the model-free approach and the other is the model-based approach.<p><strong>Model-Free Approach</strong> In this approach, the silhouette of different individuals is collectedwhich is then segmented into different parts which are then fitted with some shape whose pa-rameters are calculated to generate a multidimensional vector altering with according to video.A combination of these gives us the required information. Other types of approaches includethe Gait Energy Image (GEI) which is the average of silhouette over a gait cycle.<p><strong>Model-Based Approach</strong> In this kind of approach specific parameters are identified and matched to get the desired result. It involves identifying mathematical constructs that represent discriminative gait features with some parameters. The parameters are grouped into spatiotemporal and kinematic. Spatio-temporal parameters include the step length and height (stride) speed and gait cycle time while the kinematics include the joint rotations and the angle between different joints. This approach reliably handles the occlusion, noise, scale etc which fails in the case of model-free approaches.<p><img src="/3D-Gait-Recognition/assets/img/post/img1.png" alt="Figure 1: Model-free and Model-based approaches" /> <em>Figure 1: Model-free and Model-based approaches</em><h1 id="problem-statement">Problem Statement</h1><p><strong>3D-Gait-Recognition</strong> Creating a deep learning pipeline for the identification of the personby the manner of its walking i.e. using his/her gait features.<p><img src="/3D-Gait-Recognition/assets/img/post/gait.png" alt="Figure 2: Gait Recognition" /> <em>Figure 2: Gait Recognition</em><h2 id="dataset">Dataset</h2><p>The dataset that we will be using in the project will be the <strong>Human3.6M</strong> dataset. The dataset consists of 3.6 million different human poses collected with 4 digital cameras. The data is organized into 15 training motions containing walking with many types of asymmetries (e.g. walking with a hand in a pocket, walking with a bag on the shoulder), sitting and laying down poses, various types of waiting poses and other types of poses. The actors were given detailed tasks with examples in order to help them plan a stable set of poses between repetitions for the creation of training, validation and test sets. In the execution of these tasks the actors were however given quite a bit of freedom in moving naturally over a strict, rigid interpretation of the tasks.<h2 id="edge-device">Edge Device</h2><p><strong>Jetson Tx2</strong> : Jetson TX2 is the fastest, most power-efficient embedded AI computing device. The latest addition to the industry-leading Jetson embedded platform, this 7.5-watt supercomputer on a module brings true AI computing at the edge. It’s built around an NVIDIA Pascal™-family GPU and loaded with 8 GB of memory and 59.7 GB/s of memory bandwidth. It features a variety of standard hardware interfaces that make it easy to integrate it into a wide range of products and form factors.<p><img src="/3D-Gait-Recognition/assets/img/post/jetson.jpg" alt="Figure 3: Jetson Tx2 Module" /> <em>Figure 3: Jetson Tx2 Module</em><h2 id="pipeline">Pipeline</h2><p>Below is the proposed pipeline for the project :<ul><li>Identifying and creating the Ground Truth data.<li>Getting the individual poses for each of different concerned objects in each frame.(DensePose-RCNN)<li>Establishing the spatio-temporal relationships between the frames in the gait cycle using RNNs or LSTMs.<li>Optimizing the above network by creating TensorRT engine to work on the Nvidia Jetson Tx2.</ul><h1 id="references">References</h1><ol><li>A. Schrijver,Combinatorial Optimization - Polyhedra and Efficiency. Springer, 2003.<li>R. G. Gallager, “Low density parity check codes,”Transactions of the IRE ProfessionalGroup on Information Theory, vol. IT-8, pp. 21 –28, Jan. 1962.<li>F. Mat ́uˇs, “Infinitely many information inequalities,” inIEEE International Symposium onInformation Theory, (Nice, France), pp. 41 –44, Jun. 2007.<li>Gait recognition - https://www.youtube.com/watch?v=emjpqglx14a.”<li>“https://developer.nvidia.com/embedded/buy/jetson-tx2.”<li>N. N. R. A. Guler and I. Kokkinos, “Densepose: Dense human pose estimation in thewild,” 2018.<li>P. D. K. He, G. Gkioxari and R. G. M, “Mask rcnn,” 2017</ol></article><hr class="dingbat related" /><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content=""><meta name="author" content=""><title>Round About - Start Bootstrap Template</title><link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" rel="stylesheet"> <!--<link href="css/round-about.css" rel="stylesheet">--><style type="text/css"> body { padding-top: 54px; } @media (min-width: 992px) { body { padding-top: 56px; } }</style><body><div class="container"><div class="row"><div class="col-lg-12"><h2 class="my-4">Our Team</h2></div><div class="col-lg-2 col-sm-2 text-center mb-4"> <img class="rounded-circle img-fluid d-block mx-auto" src="/3D-Gait-Recognition/assets/img/aditya.jpeg" alt=""><h5 >Aditya Nigam <small>[Advisor]</small></h5><p><a href="http://faculty.iitmandi.ac.in/~aditya/">Webpage</a></div><div class="col-lg-2 col-sm-2 text-center mb-4"> <img class="rounded-circle img-fluid d-block mx-auto" src="/3D-Gait-Recognition/assets/img/daksh.jpg" alt=""><h5>Daksh Thapar <small>[Mentor]</small></h5><p><a href="https://students.iitmandi.ac.in/~s16007/">Webpage</a></div><div class="col-lg-2 col-sm-2 text-center mb-4"> <img class="rounded-circle img-fluid d-block mx-auto" src="/3D-Gait-Recognition/assets/img/abhijeet.jpg" alt=""><h5>Abhijeet Sharma <small>[Mentee]</small></h5><p><a href="https://abhijeet2096.me/">Webpage</a></div><div class="col-lg-2 col-sm-2 text-center mb-4"> <img class="rounded-circle img-fluid d-block mx-auto" src="/3D-Gait-Recognition/assets/img/mohit.jpeg" alt=""><h5>Mohit Sharma <small>[Mentee]</small></h5><p><a href="https://www.linkedin.com/in/mohit21sharmams/">Webpage</a></div><div class="col-lg-2 col-sm-2 text-center mb-4"> <img class="rounded-circle img-fluid d-block mx-auto" src="/3D-Gait-Recognition/assets/img/akhil.jpeg" alt=""><h5>Akhil Singhal <small>[Mentee]</small></h5><p><a href="https://www.linkedin.com/in/akhil-singhal-a59448106/">Webpage</a></div></div></div><script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script> <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"></script><aside class="comments related" role="complementary"><h2 class="hr">Comments</h2><div id="disqus_thread"></div><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript></aside><footer role="contentinfo"><hr/><p><small class="copyright">© 2017. All rights reserved. </small><p><small>Powered by <a class="external" href="https://qwtel.com/hydejack/">Hydejack</a> v<span id="_version">7.5.0</span></small><hr class="sr-only"/></footer></main><hy-drawer><header id="_sidebar" class="sidebar" role="banner"><div class="sidebar-bg sidebar-overlay" style="background-color:#4fb1ba;background-image:url(/assets/img/back.png)"></div><div class="sidebar-sticky"><div class="sidebar-about"><h2 class="h1"><a href="/">3D Gait Recognition</a></h2><p class=""> Deep Learning Project based on 3D Gait Recognition</div><nav class="sidebar-nav heading" role="navigation"> <span class="sr-only">Navigation:</span><ul><li> <a id="_navigation" href="/about/" class="sidebar-nav-item" > About </a></ul></nav><div class="sidebar-social"> <span class="sr-only">Social:</span><ul><li> <a href="https://twitter.com/SharmaJeKaBeta" title="Twitter" class="no-mark-external"> <span class="icon-twitter"></span> <span class="sr-only">Twitter</span> </a><li> <a href="https://github.com/abhijeet2096" title="GitHub" class="no-mark-external"> <span class="icon-github"></span> <span class="sr-only">GitHub</span> </a><li> <a href="https://facebook.com/Sharmajeekabeta" title="Facebook" class="no-mark-external"> <span class="icon-facebook"></span> <span class="sr-only">Facebook</span> </a></ul></div></div></header></hy-drawer> </hy-push-state> <!--[if gt IE 9]><!----> <script>loadJSDeferred('/assets/js/hydejack-7.5.0.js');</script> <!--<![endif]--><hr class="sr-only"/><h2 class="sr-only">Templates (for web app):</h2><template id="_animation-template"><div class="animation-main fixed-top"><div class="content"><div class="page"></div></div></div></template> <template id="_loading-template"><div class="loading"> <span class="sr-only">Loading…</span> <span class="icon-cog"></span></div></template> <template id="_error-template"><div class="page"><h1 class="page-title">Error</h1><p class="lead"> Sorry, an error occurred while loading <a class="this-link" href=""></a>.</div></template> <template id="_back-template"> <a id="_back" class="back nav-btn no-hover"> <span class="sr-only">Back</span> <span class="icon-arrow-left2"></span> </a> </template> <template id="_permalink-template"> <a href="#" class="permalink"> <span class="sr-only">Permalink</span> <span class="icon-link"></span> </a> </template></html>
